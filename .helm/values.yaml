# Default values for flts.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# This will set the replicaset count more information can be found here: https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/
replicaCount: 1

# This sets the container image more information can be found here: https://kubernetes.io/docs/concepts/containers/images/
image:
  repository: nginx
  # This sets the pull policy for images.
  pullPolicy: IfNotPresent
  # Overrides the image tag whose default is the chart appVersion.
  tag: ""

# This is for the secrets for pulling an image from a private repository more information can be found here: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
imagePullSecrets: []
# This is to override the chart name.
nameOverride: ""
fullnameOverride: ""

# This section builds out the service account more information can be found here: https://kubernetes.io/docs/concepts/security/service-accounts/
serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Automatically mount a ServiceAccount's API credentials?
  automount: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

# This is for setting Kubernetes Annotations to a Pod.
# For more information checkout: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
podAnnotations: {}
# This is for setting Kubernetes Labels to a Pod.
# For more information checkout: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
podLabels: {}

podSecurityContext: {}
  # fsGroup: 2000

securityContext: {}
  # capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
  # runAsUser: 1000

# This is for setting up a service more information can be found here: https://kubernetes.io/docs/concepts/services-networking/service/
service:
  # This sets the service type more information can be found here: https://kubernetes.io/docs/concepts/services-networking/service/#publishing-services-service-types
  type: ClusterIP
  # This sets the ports more information can be found here: https://kubernetes.io/docs/concepts/services-networking/service/#field-spec-ports
  port: 80

# This block is for setting up the ingress for more information can be found here: https://kubernetes.io/docs/concepts/services-networking/ingress/
ingress:
  enabled: false
  className: ""
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  hosts:
    - host: chart-example.local
      paths:
        - path: /
          pathType: ImplementationSpecific
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

# This is to setup the liveness and readiness probes more information can be found here: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
livenessProbe:
  httpGet:
    path: /
    port: http
readinessProbe:
  httpGet:
    path: /
    port: http

# This section is for setting up autoscaling more information can be found here: https://kubernetes.io/docs/concepts/workloads/autoscaling/
autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 100
  targetCPUUtilizationPercentage: 80
  # targetMemoryUtilizationPercentage: 80

# Additional volumes on the output Deployment definition.
volumes: []
# - name: foo
#   secret:
#     secretName: mysecret
#     optional: false

# Additional volumeMounts on the output Deployment definition.
volumeMounts: []
# - name: foo
#   mountPath: "/etc/foo"
#   readOnly: true

nodeSelector: {}

tolerations: []

affinity: {}

# ---------------------------------------------------------------------------
# ---------------------------------------------------------------------------

persistence:
  enabled: true

global:
  storageClass: "standard"
  pullPolicy: IfNotPresent

# KAFKA
kafka:
  image:
    repository: apache/kafka
    tag: "3.9.1"
  service:
    port: 9092
    controllerPort: 9093
  config:
    nodeId: 1
    replicationFactor: 1
    groupInitialRebalanceDelayMs: 0

# FASTAPI
fastapi:
  enabled: true
  image:
    repository: fastapi-app
    tag: "latest"
  service:
    port: 8000
  env:
    minioFile: ".env.minio"

# MINIO
minio:
  image:
    repository: minio/minio
    tag: "latest"
  service:
    apiPort: 9000
    consolePort: 9001
  auth:
    accessKey: "minioadmin"
    secretKey: "minioadmin"
  env:
    defaultBucket: "dataset"
  storage:
    size: "10Gi"

# MLFLOW
mlflow:
  enabled: true
  image:
    repository: mlflow
    tag: "latest"
  service:
    port: 5000
  postgres:
    image:
      repository: postgres
      tag: "13"
    service:
      port: 5432
    auth:
      user: "mlflow"
      password: "mlflow"
      database: "mlflow"
    resources:
      requests:
        memory: "512Mi"
        cpu: "250m"
      limits: 
        memory: "1Gi"
        cpu: "500m"
    storage:
      size: "5Gi"




# ---------- Pipeline ----------

eda:
  image:
    repository: eda
    tag: "latest"
  service:
    port: 8010

preprocess:
  image:
    repository: preprocess
    tag: latest
    pullPolicy: IfNotPresent
  service:
    port: 8020
  job:
    parallelism: 1
    restartPolicy: OnFailure
  scaler: MinMaxScaler
  kafka:
    topics:
      training: "training-data"
      inference: "inference-data"

# Training Job
train:
  enabled: false
  image:
    repository: train
    tag: latest
  service:
    port: 8021
  job:
    parallelism: 1
    restartPolicy: OnFailure
  kafka:
    consumerTopic: "training-data"
    consumerGroupId: "train"
    producerTopic: "model-training"
  env:
    consumerGroupId: "train"
    consumerTopic: "training-data"
    producerTopic: "model-training"
    kafkaBootstrapServers: "kafka:9092"
    gatewayUrl: "http://fastapi-app:8000"
    awsAccessKeyId: minioadmin
    awsSecretAccessKey: minioadmin
    mlflowS3EndpointUrl: "http://minio:9000"
    mlflowTrackingUri: "http://mlflow:5000"
  resources:
    requests:
      memory:
      cpu: "6000m"
    limits:
      memory:
      cpu: "8000m"

  model:
    type: "LSTM" # "GRU" | "TETS" | "TCN"

    trainTestSplit: 0.8 # percentage of training data to use on training the model vs evaluating it (during training). Use a different set for final performance rating to catch overfitting
    inputSeqLen: 10 # number of points for the model to use to predict
    outputSeqLen: 1 # number of points for the model to predict (accuracy suffers exponentially with this). However, recursive inferencing still allows for decent forecast horizons

    batchSize: 32 # how many points are shown to the model at once, higher = faster but more memory (no effect on accuracy)
    learningRate: 0.001 # you almost never need to change this, raise if converging but taking forever, lower if struggling to converge
    numEpochs: 100 # set to a high value and use early stopping, otherwise, check mlflow loss graph for plateau
    earlyStopping: true # trains until numEpochs is reached or the number of cumulative epochs without improvement in loss exceeds patience
    patience: 30 # start with a reasonable value and lower if necessary

    LSTM:
      hiddenSize: 128 # Neurons per layer (how "wide" the model is)
      numLayers: 4 # how "deep" the model is

    GRU:
      hiddenSize: 128
      numLayers: 4

    TETS:
      modelDim: 128
      numHeads: 8
      feedforewardDim: 512
      dropout: 0.1

    TCN:
      layerArchitecture: [32, 64, 128, 256]
      kernelSize: 2
      dropout: 0.1

  # Non-ML Job
nonml:
  enabled: true
  image:
    repository: nonml
    tag: "latest"
  service:
    port: 8022
  kafka:
    consumerTopic: "training-data"
    consumerGroupId: "nonml"
    producerTopic: "model-training"
  model:
    type: "AUTOMFLES" # PROPHET | AUTOARIMA | AUTOETS | AUTOTHETA | AUTOMFLES | AUTOTBATS
    downsampling: 0 # 0 for original periodicity, otherwise pandas compatible time string
    seasonLength: 720 # integer multiple of periodicity representing most relevant seasonality (recommended smallest relevant seasonality because big numbers get very slow)
  resources:
    requests:
      memory:
      cpu: "6000m"
    limits:
      memory:
      cpu: "8000m"

# Inference Service
inference:
  image:
    repository: inference
    tag: "latest"
  service:
    port: 8023
  kafka:
    consumerTopics:
      - "inference-data"
      - "model-training"
    consumerGroupId: "batch-forecasting"
    producerTopic: "performance-eval"
  config:
    sampleIdx: 0
    inferenceLength: 4070
